{
  "hash": "7cea9fac6035371e11895079fa291453",
  "result": {
    "engine": "knitr",
    "markdown": "# Missingness and measurement {#sec-missingness}\n\n\n\n\n\n\n\n\n\n\n\n\nMissing and mismeasured data are problems for most real datasets that impact all three types of analysis: description, prediction, and causal inference.\nAs with analysis, the impact of missingness and mismeasurement is also different across all three, even when we use the same tools (like multiple imputation) to address it.\nAt their best, missingness and mismeasurement can worsen the precision and bias of the sample; at their worst, they can create unresolvable selection bias, giving you a completely wrong answer.\nIn this chapter, we'll explore how bias can arise in causal analyses in the presence of missingness and mismeasurement and how to address them (if we can!).\n\n## Missingness and measurement error as structural bias\n\nIt's frequently been observed that causal inference can be thought of fundamentally as a missing data problem; after all, we want to compare counterfactual states, but all such states outside of the factual world are missing.\nCausal inference as missingness is interesting philosophically and connects methods from the two areas of statistics.\nHere, we'll consider the reverse proposition: missingness and measurement error are causal inference problems.\n\nThus far, we've made a big assumption in our DAGs that the variables we've included are actually the variables in our data.\nIn other words, we assume that the data is measured perfectly and completely.\nThis assumption is almost always untrue.\nLet's consider a few scenarios using causal diagrams to understand the impact of mismeasurement and missingness.\n\n::: callout-tip\nIf `x` is partially missing but `y` is not, you can measure the mean of `y` with a higher sample size than the mean of `x`.\nHowever, for joint parameters, like a regression coefficient, you can only calculate the value for observations where both `x` and `y` are complete.\nMany tools in R, like `lm()`, quietly drop rows that are not complete for necessary variables by default.\n\nUsing only observation where the needed variables are all complete is sometimes called a *complete-case analysis*, which we've been doing thus far in the book.\n:::\n\nIn the TouringPlans data, most variables are complete and likely accurately measured (e.g., ticket season and historic weather are well-measured).\nOne variable with missingness and measurement error is the actual wait times for rides.\nIf you recall, the data relies on humans to wait in line, either consumers of the data who report their experience or people hired to wait in line to report the wait time.\nThus, missingness is primarily related to whether someone is there to measure the wait time.\nWhen someone is there to measure it, it's also likely measured with error, and that error likely depends on who the person is. For example, a visitor to Disney World estimating their wait time and submitting it to TouringPlans is likely producing a value with more error than someone paid to stay in line and count the minutes.\n\nThat said, let's take measurement error and missingness one at a time.\n\n### Structural measurement error\n\nFirst, let's consider measurement error.\nIn @fig-meas-err-dag, we represent actual and posted wait times twice: the true version and the measured version.\nThe measured versions are influenced by two variables: the real values and unknown or unmeasured factors that influence their mismeasurement.\nHow the two wait times are mismeasured are independent of one another.\nFor simplicity, we've removed the confounders from this DAG.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A DAG showing the relationship between posted and actual wait times, with additional information about measurement. The mismeasured versions of the two wait time variables are represented as separate nodes. The mismeasured versions are caused by the true values and an unknown mechanism that worsens measurement. When conducting a causal analysis with mismeasured variables, we use them as proxies for the true values.](17-missingness-and-measurement_files/figure-html/fig-meas-err-dag-1.png){#fig-meas-err-dag width=672}\n:::\n:::\n\n\n\n\n\nTouringPlans scraped the posted wait times from what Disney posts on the web.\nThere is a plausible mechanism by which this could be mismeasured: Disney could post the wrong times online compared to what's posted at the park, or TouringPlans could have a mistake in its data acquisition code.\nThat said, it's reasonable to assume this error is small.\n\nOn the other hand, actual wait times probably have a lot of measurement error.\nHumans have to measure this period manually, so that process has some natural error.\nMeasurement also likely depends on whether or not the person measuring the wait time is being paid to do so.\nPresumably, someone entering it out of goodwill is more likely to submit an approximate wait time, and someone who is paid is more likely to be precise.\n\nSo, an updated DAG might look like @fig-meas-err-other-1.\nThis DAG describes the structural causes of measurement error in `actual`; notably, that structure is not connected to `posted`.\nIt is easier to see if we show a *null* DAG with no arrow from `posted` to `actual` (@fig-meas-err-other-2).\nPosted time is not connected to the mechanisms that cause measurement error in actual time.\nIn other words, the bias caused by this measurement error is *not* due to nonexchangeability; it's due to a numerical error in the measurement, not an open path in the causal graph.\nThe extent of this error depends on how well the measured version correlates with the real values.\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![An updated DAG where the measured version of posted wait times is only caused by the true value, meaning it is perfectly measured. For the actual wait times, the three causes are the true values, whether or not TouringPlans employed the reporter, and an unknown mismeasurement mechanism.](17-missingness-and-measurement_files/figure-html/fig-meas-err-other-1.png){#fig-meas-err-other-1 width=384}\n:::\n\n::: {.cell-output-display}\n![A null DAG, meaning we have removed the arrow from actual wait times to posted wait times. When we look at a null DAG, we can see the mechanisms of mismeasurement are separate for the two wait time variables.](17-missingness-and-measurement_files/figure-html/fig-meas-err-other-2.png){#fig-meas-err-other-2 width=384}\n:::\n:::\n\n\n\n\n\nInstead of the type of nonexchangeability induced by confounding, this type of measurement bias is due to the fact that we're analyzing the effect of `posted_measured` to `actual_measured` as a proxy for the effect of `posted` on `actual`.\nThe correctness of the result depends entirely on how well `actual_measured` approximates `actual`.\nIf you change your point of view to treating the measured variables as the cause and effect under study, you'll see that we're actually using the causal structure to approximate the study of the real variables.\nThe measured variables in @fig-meas-err-other-1 do not cause one another.\nHowever, if we calculate their relationship, they'll be confounded by the real variables.\nUnusually, we're using this confounding to approximate the relationship in the real variables.\nThe extent to which we can do that depends on exchangeability *with the exception of the real variables* and the amount of independent measurement error for each variable (such as `unknown` here).\n\nThis is sometimes called *independent, non-differential* measurement error: the error is not due to structural nonexchangeability but the differences in the observed and real values for actual and posted times.\n\n::: callout-warning\nAs the correlation approaches 0, measurement becomes random for the relationship under study.\nThis often means that when variables are measured with independent measurement error, the relationship of the measured values approaches null even if there is an arrow between the true values.\nHere, the coefficient of `x` should be about 1, but as the random measurement worsens, the coefficient gets closer to 0. There's no relationship between the randomness (`u`) induced by mismeasurement and `y`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 1000\nx <- rnorm(n)\ny <- x + rnorm(n)\n# bad measurement of x\nu <- rnorm(n)\nx_measured <- .01 * x + u\ncor(x, x_measured)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.01177\n```\n\n\n:::\n\n```{.r .cell-code}\nlm(y ~ x_measured)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x_measured)\n\nCoefficients:\n(Intercept)   x_measured  \n    -0.0181      -0.0327  \n```\n\n\n:::\n:::\n\n\n\n\n\nNot all random mismeasurement will bring the effect towards the null, however.\nFor instance, for categorical variables with more than two categories, mismeasurement changes the distribution of counts of their values (this is sometimes called misclassification for categorical variables).\nEven in random misclassification, some of the relationships will be biased towards the null and some away from the null simply because when counts are removed from one category, they go into another.\nFor instance, if we randomly mix up the labels `\"c\"` and `\"d\"`, they average towards each other, making the coefficient for `c` too big and the coefficient for `d` too small, while the other two remain correct.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nx <- sample(letters[1:5], size = n, replace = TRUE)\ny <- case_when(\n  x == \"a\" ~ 1 + rnorm(n),\n  x == \"b\" ~ 2 + rnorm(n),\n  x == \"c\" ~ 3 + rnorm(n),\n  x == \"d\" ~ 4 + rnorm(n),\n  x == \"e\" ~ 5 + rnorm(n),\n)\n\nx_measured <- ifelse(\n  x %in% c(\"c\", \"d\"), \n  sample(c(\"c\", \"d\"), size = n, replace = TRUE),\n  x\n)\n\nlm(y ~ x_measured)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x_measured)\n\nCoefficients:\n(Intercept)  x_measuredb  x_measuredc  x_measuredd  \n      0.984        0.917        2.636        2.530  \nx_measurede  \n      3.931  \n```\n\n\n:::\n:::\n\n\n\n\n\nSome researchers rely on the hope that random measurement error is predictably towards the null, but this isn't always true.\nSee @Yland2022 for more details on when this is false.\n:::\n\nHowever, let's say that a single unknown factor affects the measurement of both the posted wait time and actual wait time, as in @fig-meas-err-dag-dep-1.\nIn addition to the problem above, there's also nonexchangeability because of confounding in the measured variables (@fig-meas-err-dag-dep-2).\nThis is called *dependent, non-differential* measurement error.\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Now, the DAG includes an arrow from `unknown` to both measured variables, meaning that the way they are mismeasured is not independent. In other words, `unknown` is now a mutual cause of the mismeasured variables---a confounder.](17-missingness-and-measurement_files/figure-html/fig-meas-err-dag-dep-1.png){#fig-meas-err-dag-dep-1 width=384}\n:::\n\n::: {.cell-output-display}\n![The open paths in this DAG. Because this is a null DAG, the only open pathway is a biasing one from the two mismeasured variables via `unknown`.](17-missingness-and-measurement_files/figure-html/fig-meas-err-dag-dep-2.png){#fig-meas-err-dag-dep-2 width=384}\n:::\n:::\n\n\n\n\n\nWhen the nonexchangeability is related to the exposure, outcome, or both, it's called *differential* measurement error, which can be dependent or independent.\nLet's expand @fig-meas-err-dag-dep-1 to include an arrow from posted time to how actual wait time is measured, a case of *dependent, differential* measurement error (without the path introduced in @fig-meas-err-dag-dep-1, it would be *independent* and differential).\n@fig-meas-err-dag-diff shows two open backdoor paths: the path via `unknown` and the path via `posted`.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![When the true value of posted wait times affects the measurement of both measured variables, it becomes a confounder for them. When the backdoor path is due to either the exposure or the outcome, it's classified as differential measurement error.](17-missingness-and-measurement_files/figure-html/fig-meas-err-dag-diff-1.png){#fig-meas-err-dag-diff width=720}\n:::\n:::\n\n\n\n\n\nThe names of the types of measurement error are conceptual.\nIn reality, there are just two forms of bias happening: numerical inconsistency of the measured variables with their real values (independent, non-differential measurement error) and nonexchangeability (the other three types of measurement error).\nWhether the error is dependent or differential is based on whether the nonexchangeability involves the exposure and/or the outcome.\n\nOne inconvenience of the dependent/differential groupings is that it masks the fact that these two sources of bias can and do occur together.\nOften, all of these circumstances occur together (numerical inconsistency with the true values and open backdoor paths involving the exposure/outcome as well as other paths).\nIn this case, the bias is due to *both* how well the measured variable correlates with the true variable and structural nonexchangeability.\n\nIn this case, posted time is unlikely to impact the measurement quality of actual time, so we can probably rule the extra arrow in @fig-meas-err-dag-diff out (although we'll see below that it may affect the *missingness* of actual time).\nThe measurement of posted times also probably occurs before the measurement of actual time, so there can't be an arrow there.\n\n::: callout-tip\nThe reason why we can have a situation where, for instance, the outcome affects the measurement of the exposure is that the measurement of variables may not match the time-ordering of the values they represent.\nAn exposure may happen long before an outcome, but their measurement could happen in any order.\nUsing values *measured* in time order helps avoid some types of measurement error, such as when the outcome impacts the measurement of the exposure.\nEither way, correctly representing occurrence and measurement in your DAG can help you identify and understand problems.\n:::\n\nMismeasured confounders also cause problems.\nFirstly, if we have a poorly measured confounder, we may not have closed the backdoor path completely, meaning there is residual confounding.\nSecondly, mismeasured confounders can also appear to be effect modifiers when the mismeasurement is differential with respect to the outcome.\nUsually, the bias from the residual confounding is worse, but there is often a small but significant interaction effect between the exposure and the mismeasured confounder, as shown in @tbl-confounder-me.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 10000\nset.seed(1)\nconfounder <- rnorm(n)\nexposure <- confounder + rnorm(n)\noutcome <- exposure + confounder + rnorm(n)\n\ntrue_model <- lm(outcome ~ exposure * confounder)\n\n# mismeasure confounder\nconfounder <- ifelse(\n  outcome > 0, \n  confounder, \n  confounder + 10 * rnorm(n)\n)\n\nmismeasured_model <- lm(outcome ~ exposure * confounder)\n```\n:::\n\n::: {#tbl-confounder-me .cell tbl-cap='The coefficients of interaction terms between a confounder and the exposure. In one mode, the confounder is measured correctly. In another, it is mismeasured differentially by the outcome. In addition to not closing the backdoor path completely, this type of mismeasurement often appears as an interaction between the exposure and confounder, even when such an interaction does not exist.'}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"wotruodbev\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#wotruodbev table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#wotruodbev thead, #wotruodbev tbody, #wotruodbev tfoot, #wotruodbev tr, #wotruodbev td, #wotruodbev th {\n  border-style: none;\n}\n\n#wotruodbev p {\n  margin: 0;\n  padding: 0;\n}\n\n#wotruodbev .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wotruodbev .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#wotruodbev .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wotruodbev .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wotruodbev .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wotruodbev .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wotruodbev .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wotruodbev .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wotruodbev .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wotruodbev .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wotruodbev .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wotruodbev .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wotruodbev .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#wotruodbev .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#wotruodbev .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wotruodbev .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wotruodbev .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wotruodbev .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wotruodbev .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wotruodbev .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wotruodbev .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wotruodbev .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#wotruodbev .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wotruodbev .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wotruodbev .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wotruodbev .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wotruodbev .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wotruodbev .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wotruodbev .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wotruodbev .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wotruodbev .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wotruodbev .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wotruodbev .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wotruodbev .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wotruodbev .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wotruodbev .gt_left {\n  text-align: left;\n}\n\n#wotruodbev .gt_center {\n  text-align: center;\n}\n\n#wotruodbev .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wotruodbev .gt_font_normal {\n  font-weight: normal;\n}\n\n#wotruodbev .gt_font_bold {\n  font-weight: bold;\n}\n\n#wotruodbev .gt_font_italic {\n  font-style: italic;\n}\n\n#wotruodbev .gt_super {\n  font-size: 65%;\n}\n\n#wotruodbev .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#wotruodbev .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wotruodbev .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#wotruodbev .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#wotruodbev .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#wotruodbev .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#wotruodbev .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#wotruodbev .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#wotruodbev div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"model\">model</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"term\">term</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"estimate\">estimate</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"p-value\">p-value</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"model\" class=\"gt_row gt_left\">true</td>\n<td headers=\"term\" class=\"gt_row gt_left\">exposure:confounder</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">0.001</td>\n<td headers=\"p-value\" class=\"gt_row gt_left\">0.850</td></tr>\n    <tr><td headers=\"model\" class=\"gt_row gt_left\">mismeasured</td>\n<td headers=\"term\" class=\"gt_row gt_left\">exposure:confounder</td>\n<td headers=\"estimate\" class=\"gt_row gt_right\">0.009</td>\n<td headers=\"p-value\" class=\"gt_row gt_left\">&lt;0.001</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\n### Structural missingness\n\nAbove, we argued that posted wait time likely has no impact on the measurement of actual wait time.\nHowever, the posted wait time *may* influence the *missingness* of the actual wait time.\nIf the posted wait time is high, someone may not get in the line and thus not submit an actual wait time to TouringPlans.\nFor simplicity, we've removed details about measurement error and assume that the variables are well-measured and free from confounding.\n\n@fig-missing-dag-1 represents a slightly different situation than the DAGs in the measurement error examples.\nWe still have two nodes for a given variable, but one represents the true values, and the other represents a *missingness indicator*, whether the value is missing or not.\nThe problem is that we are inherently conditioning whether or not we observed the data.\nWe are always conditioning on the data we actually have.\nIn the case of missingness, we're usually talking about conditioning on *complete* observations, e.g., we're using the subset of data where all the values are complete for the variables we need.\nIn the best case, missingness is unrelated to the causal structure of the research question, and the only impact is a reduction in sample size (and thus precision).\n\nIn @fig-missing-dag-1, though, we're saying that the missingness of `actual` is related to the posted wait times and to an unknown mechanism.\nThe unknown mechanism is random, but the mechanism related to posted wait times is not since it's the exposure.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A DAG representing the missingness structure of actual wait time. In this DAG, missingness is caused by posted wait times and an unknown mechanism that affects whether or not actual wait times are measured. Missingness in actual wait times is represented as a separate node, a missingness indicator.](17-missingness-and-measurement_files/figure-html/fig-missing-dag-1-1.png){#fig-missing-dag-1 width=480}\n:::\n:::\n\n\n\n\n\nHowever, in this simple DAG, conditioning on missingness does not open a backdoor path between `actual` and `posted`.\n(It does bias the relationship between `unknown` and `posted`, but we don't care about that relationship even if we could estimate it.) The only open path in @fig-missing-dag-2 is the one from `posted` to `actual`.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![In DAGs with missingness, we are also conditioning on the missingness indicators because we're stratifying by whether or not we have a given variable. In this DAG, even though `missing` is a collider, stratifying on it does not open a backdoor path between the exposure and outcome.](17-missingness-and-measurement_files/figure-html/fig-missing-dag-2-1.png){#fig-missing-dag-2 width=384}\n:::\n:::\n\n\n\n\n\nBecause we don't have exchangeability issues, we should still be able to estimate a causal effect.\nMissingness still impacts the analysis, though.\nThe causal effect in this case is *recoverable*; we can still estimate it without bias with complete-case analysis.\nHowever, because we're only using observations with complete observation, we have a smaller sample size and thus reduced precision.\nWe are also now unable to correctly estimate the *mean* of actual wait times because values are systematically missing by posted wait time.\n\nIs it feasible that the missingness of `actual` is related to its own values?\nIt could be that the actual wait times are so fast that a rider doesn't have time to enter them, or it could be such a long wait that they decide to get out of line.\n@fig-missing-dag-actual-1 depicts a relationship like this.\n\nWhen missingness is collider, conditioning on it may induce bias.\nIn this case, whether or not actual wait times were measured is a descendant of both the actual and posted wait times.\nConditioning on it opens a backdoor path, creating nonexchangeability, as in @fig-missing-dag-actual-2.\nIn this case, there is no way to close the backdoor paths opened by conditioning on missingness.\n\n\n\n\n\n::: {.cell layout-ncol=\"2\"}\n::: {.cell-output-display}\n![Now, the DAG includes an arrow from actual wait times to the missingness indicator for actual wait times. In other words, the values of actual wait times themselves influence whether or not we've managed to measure them.](17-missingness-and-measurement_files/figure-html/fig-missing-dag-actual-1.png){#fig-missing-dag-actual-1 width=480}\n:::\n\n::: {.cell-output-display}\n![Conditioning on the missingness indicator now opens a backdoor path between the exposure and the outcome, and we have no means to close it.](17-missingness-and-measurement_files/figure-html/fig-missing-dag-actual-2.png){#fig-missing-dag-actual-2 width=480}\n:::\n:::\n\n\n\n\n\nWhat effects we can recover is more complicated than determining backdoor paths alone.\nWhen there are no backdoor paths, we can calculate the causal effect, but we may not be able to calculate other statistics like the mean of the exposure or outcome.\nWhen conditioning on missingness opens a backdoor path, sometimes we can close it (and thus estimate a causal effect), and sometimes we can't.\n\nConsider the DAGs in @fig-missing-dags-sim, where `a` is `actual`, `p` is `posted`, `u` is `unknown`, and `m` is `missing`.\nEach of the DAGs represents a simple but differing structure of missingness.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![5 DAGs where `a` is `actual`, `p` is `posted`, `u` is `unknown`, and `m` is `missing`. Each DAG represents a slightly different missingness mechanism. In DAGs 1-3, the actual wait time values have missingness; in DAGs 4-5, some posted wait times are missing. The causal structure of missingness impacts what we can estimate.](17-missingness-and-measurement_files/figure-html/fig-missing-dags-sim-1.png){#fig-missing-dags-sim width=672}\n:::\n:::\n\n\n\n\n\n@fig-recoverables presents the mean of `posted` and `actual` and the estimated causal effect of `posted` on `actual` for data simulated from these DAGs.\nWithout any missingness, of course, we can estimate all three.\nFor DAG 1, we can also estimate all three, but because of missingness, we have a reduced sample size and, thus, worse precision.\nFor DAG 2, we can calculate the mean of `posted` and the causal effect but not the mean of `actual`.\nFor DAG 3, we also can't calculate the causal effect.\nIn DAG 4, we can calculate the mean of `actual` and the causal effect but not the mean of `posted`, and in DAG 5, we can calculate the mean of `actual`, but that's it.\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A forest plot of the results of three different effects for data simulated from each DAG in @fig-missing-dags-sim. In the non-missing results, we can see what the effect should be for the sample. Each simulated dataset has 365 rows with missingness in either actual or posted wait times. For each of the DAGs, we're limited in what we can estimate correctly.](17-missingness-and-measurement_files/figure-html/fig-recoverables-1.png){#fig-recoverables width=672}\n:::\n:::\n\n\n\n\n\nSee @Moreno-Betancur2018 for a comprehensive overview of what effects are recoverable from different structures of missingness.\n\nAs in measurement error, the confounders in the causal model may also contribute to the missingness of actual wait time, such as if season or temperature influences whether TouringPlans sends someone in to do a measurement.\nIn these data, all the confounders are observed, but missingness in confounders can cause both residual confounding and selection bias from stratification on complete cases.\n\n::: callout-tip\nIn the grand tradition of statisticians being bad at naming things, you'll also commonly see missingness discussed in terms of *missing completely at random*, *missing at random*, and *missing not at random*.\n\nIn the case of causal models, we can explain these ideas by the causal structure of missingness and the availability of variables and values related to that structure in your data.\n\n-   **Missing completely at random (MCAR)**: there are missing values, but the causes of missingness are such that the missingness process is unrelated to the causal structure of your question. In other words, the only problem with missingness is a reduction in sample size.\n-   **Missing at random (MAR)**: the causes of missingness are related to the causal structure of the research problem, but it only depends on the variables and values in the data that we've actually observed.\n-   **Missing not at random (MNAR)**: the causes of missingness are related to the causal structure of the research problem, but this process is related to values we are missing. A classic example is when a variable's missingness is impacted by itself, e.g., higher values of `x` are more likely to be missing in `x`. We don't have that information because, by definition, it's missing.\n\nThese terms don't always tell you what to do next, so we'll avoid them in favor of explicitly describing the missingness generation process.\n:::\n\nIs measurement error missingness because we're missing the true value?\nIs missingness measurement error, because we've badly mismeasured some values as `NA`?\nWe've presented the two problems using different structures, where measurement error is represented by calculating the causal effects of proxy variables, and missingness is represented by calculating the causal effects of the true variables conditional on missingness.\nThese two structures better illuminate the biases that emerge from the two situations.\nThat said, it can also be helpful to think of them from the other perspective.\nFor instance, thinking about measurement error as a missingness problem allows you to use techniques like multiple imputation to address it.\n\nOf course, we often do both because data are missing for some observations and observed but mismeasured for others.\n\nNow, let's discuss some analytic techniques for addressing measurement error and missingness to correct for both the numerical issues and structural nonexchangeability we see in these DAGs.\nIn [Chapter -@sec-sensitivity], we'll also discuss sensitivity analyses for missingness and measurement error.\n\n## Regression Calibration\n\nSometimes, you have a well-measured version of a variable for a subset of observations and a version with more measurement error for a more significant proportion of the dataset.\nWhen this is the case, you can use a simple approach called *regression calibration* to predict the value of the well-measured version for more observations in the dataset.\nThis technique's name refers to the fact that you're recalibrating the variable that you've observed more of, given the subset of values you have for the well-measured version.\nBut other than that, it's just a prediction model that includes the version of the variable you have more observations of and other variables you find essential to the measurement process.\n\nAs we know, the actual wait times have a lot of missingness.\nWhat if we considered posted wait times a proxy for actual wait times?\nIn this case, we could redo the analysis of Extra Magic Morning's effect on the calibrated version of actual wait times.\n\nFirst, we'll fit a model to predict `wait_minutes_actual_avg` using `wait_minutes_posted_avg`.\nWhere `wait_minutes_actual_avg` is available, we'll use that.\nIf it's `NA`, we'll use the calibrated value.\n\n<!-- TODO: should we include the confounders in this model? They're also in the later model. Not quite analagous to multiple imputation but closer to the idea of including predictors of censoring in censoring weights even if they're confounders in the later models. We also don't care if we induce a relationship between them and outcome because the coefficients themselves don't matter -->\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(splines)\nlibrary(touringplans)\nlibrary(broom)\ncalib_model <- lm(\n  wait_minutes_actual_avg ~\n    ns(wait_minutes_posted_avg, df = 4) * wait_hour +\n    park_temperature_high + park_close + park_ticket_season,\n  # use log of `wait_minutes_actual_avg`\n  data = seven_dwarfs_train_2018 |> \n    mutate(wait_minutes_actual_avg = log1p(wait_minutes_actual_avg))\n)\n\nseven_dwarves_calib <- calib_model |> \n  augment(newdata = seven_dwarfs_train_2018) |> \n  rename(wait_minutes_actual_calib = .fitted) |> \n  # convert back to the original scale \n  # and fill in real values where they exist\n  mutate(\n    wait_minutes_actual_calib = exp(wait_minutes_actual_calib) - 1,\n    wait_minutes_actual_calib = coalesce(\n      wait_minutes_actual_avg, \n      wait_minutes_actual_calib\n    )\n  )\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\nFitting this model with the IPW estimator results in an effect of 3.11, considerably attenuated compared to the values of `wait_minutes_posted_avg`.\n\n::: callout-warning\nThe regression calibration model introduces uncertainty into the estimates of calibrated variables.\nBe sure to include the fitting of this model in your bootstrap to get the correct standard errors.\n:::\n\n## Multiple Imputation {#sec-imputation}\n\n## Combining MICE and IPW\n\n<!-- For the end of the chapter -->\n\n::: callout-tip\nThe effects of missingness on results and the impact of complete case analyses and multiple imputation can be deeply unintuitive.\nWhen you add measurement error and other types of bias, it can be nearly impossible to reason about.\nA partial solution to this problem is to offload some of the reasoning from your brain into the computer.\n\nWe recommend writing down the causal mechanisms you think are involved in your research question and then using simulation to probe different strategies.\n\n1.  Create a DAG that includes the missingness and mismeasurement generation process and any other types of bias you think are essential.\n2.  Simulate data that match this process. Often, you'll want to simulate it to match different assumptions, such as the strength of mismeasurement or missingness related to variables in the DAG.\n3.  Check the results under different analysis strategies, such as complete-case analysis vs. imputation. You may also want to calculate the nominal coverage for the confidence intervals (the proportion of confidence intervals attained through your simulation that contain the true value; e.g., for 95% confidence intervals, 95% of the confidence intervals from your simulation should contain the true result).\n\nAs with our general suggestion about DAGs, if you are unsure about the correct DAG, you should check to see how these results differ depending on the specification.\n:::\n",
    "supporting": [
      "17-missingness-and-measurement_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}