# Estimating counterfactuals {#sec-counterfactuals}

{{< include 00-setup.qmd >}}

```{r}
#| echo: false
# TODO: remove when first edition complete
status("wip")
```

> Two roads diverged in a yellow wood, And sorry I could not travel both And be one traveler, long I stood And looked down one as far as I could To where it bent in the undergrowth --- Robert Frost

In 2022, Ice-T, best known as an American rapper and Fin on *Law and Order: SVU*, co-authored a book titled *Split Decision: Life Stories* [@split].
In Split Decision, Ice-T recounts his dramatic journey from a life of crime to fame and success, contrasting it with the fate of his former crime partner and co-author, Spike.
Both men grew up in gang-dominated neighborhoods in Los Angeles and committed jewelry heists together.
Their lives diverged when Ice-T was discovered rapping in a club, leading him to leave behind his criminal past and launch a successful music, film, and television career.
Meanwhile, Spike was caught in a jewelry robbery and imprisoned for three years.
He continued his life of crime, culminating in a botched robbery that led to a 35-year to life prison sentence.
The copy for the book describes "two men with two very different lives reveal how their paths might have very well been reversed if they made different choices".

This compelling premise implies that we are observing *counterfactuals*: two lives that follow the same trajectory until one decision (one more heist vs. pursuing a music career) diverges them: in one life, jail, and in another, success and fame.
The book begins by setting up all the ways Ice-T and his friend Spike were similar before this divergence (both grew up in Los Angeles neighborhoods, were involved with gangs, worked together to orchestrate a series of jewelry heists, etc).
Then something happens: Ice-T abandons criminal life, and Spike makes the opposite decision.
What happens next for Ice-T includes fame and fortune, while Spike ends up with 35 years to life in prison.
This book attempts a small study: two people who, before an event, were the same and, after, were different.
Spike's outcomes serve as the counterfactual to Ice-T's.

::: {#tbl-causal-map layout-ncol="1"}
```{mermaid}
%%| echo: false
flowchart LR
A{Ice-T} --> |observed| B(Abandons criminal life)
A -.-> |missing counterfactual| C(Does one more heist)
C -.-> D[35 years in prison]
B --> E[Fame & Fortune]

classDef grey fill:#ddd
class D,C grey
```

```{mermaid}
%%| echo: false
flowchart LR
A{Spike} -.-> |missing counterfactual| B(Abandons criminal life)
A --> |observed| C(Does one more heist)
C --> D[35 years in prison]
B -.-> E[Fame & Fortune]
classDef grey fill:#ddd
class E,B grey
```

Ice-T and Spike Causal Map. For the two men, we have only one observed outcome. Their memoir implies that each as a good counterfactual for the other. Had Ice-T continued with heists, would he have ended up in jail? If Spike had quit heists, would he have had fame and fortune?
:::

We don't know what would have happened to Ice-T had he continued partnering with Spike on heists.
We also don't know what would have happened to Spike if he'd stepped away from crime like Ice-T.
We live in a single factual world where Ice-T left crime, and Spike didn't.
Yet, we can see how the two men can be each other's proxies for those *counterfactual* outcomes.
In causal inference techniques, we attempt to use observed data to simulate counterfactuals in much the same way.
Even randomized trials are limited to a single factual world, so we compare the average effects of groups with different exposures.

Nevertheless, there are several issues that we can immediately see, highlighting the difficulty in drawing such inferences.
First, while the book implies that the two individuals were similar before the decisions that diverged their fates, we can guess how they might have differed.
Would one more heist have led Ice-T to prison?
It's easier to see Spike as a good counterfactual here.
What about the other way around: if Spike had quit crime, would he have become a famous musician and actor?
Ice-T decided to leave his life of crime, but that wasn't the only factor in his success: he had enough musical talent to make a career of it.
Did Spike have Ice-T's musical talent?
Can we conclude that his life would have turned out exactly like Ice-T's if he had made the same choices?
If we want to truly estimate the causal effect of the decision to leave criminal life on Ice-T's future outcomes, we would need to observe his ultimate course both under making the decision and not.
Similarly, Spike might be different from Ice-T in hard-to-measure ways, which makes him a poorer poxy for Ice-T's counterfactuals than he first seems.
Instead of relying on a single individual, we often rely on many individuals.
We could conduct an experiment where we randomize many individuals to leave criminal life (or not) and see how this impacts their outcomes *on average* (of course, this randomized trial presents some ethical issues, which is why observational data like Ice-T and Spike's are interesting).
In any case, we must rely on statistical techniques to help construct these unobservable counterfactuals from observed data.

## Potential outcomes

Factual outcomes and counterfactual outcomes are two realizations of *potential outcomes*.
Before some cause occurs, the potential outcomes are all the things that could happen depending on what you are exposed to.
Let's say that the cause we are interested in is a particular moment in the 1980s when one decides to either quit doing jewel heists or continue.
The outcome we're interested in is whether or not the individual goes to jail.

Let's assume an exposure has two levels:

-   $X=continue$ if you continue doing jewel heists

-   $X=quit$ if you quit doing jewel heists

Under this scenario, there are two potential outcomes:

-   $Y(continue)$ the potential outcome if continue

-   $Y(quit)$ the potential outcome if quit

Only *one* of these potential outcomes will be realized, the factual one corresponding to the exposure that actually occurred.
Therefore, only one potential outcome is observable for each individual.
These exposures are defined at a particular time (in this case, a specific moment in the 1980s, right around the time Ice-T was discovered), so only one can happen to any individual.
In the case of a binary exposure, this leaves one potential outcome as *observable* and one *missing.* In fact, early causal inference methods were often framed as missing data problems; we need to make certain assumptions about the *missing counterfactuals*, the value of the potential outcome corresponding to the exposure(s) that did not occur.

Our causal effect of interest is often some difference in potential outcomes $Y(continue) - Y(quit)$ (say, probability of going to jail the following year).
In the case of Ice-T and Spike, we're interested in their individual causal effects:

-   $Y_{Ice-T}(continue) - Y_{Ice-T}(quit)$
-   $Y_{Spike}(continue) - Y_{Ice-T}(quit)$

Here, we're missing $Y_{Ice-T}(continue)$ and $Y_{Spike}(quit)$), so we can't calculate these values.
In practice, we need to use observed data as proxies for the missing potential outcomes, and we usually average them over a particular population.
To do this, though, we can't just throw some statistics at a pile of observed data; we need to meet certain *causal assumptions* that allow us to imbue observed data with the meaning of potential outcomes and their analysis with causal effects.

::: callout-note
## Counterfactuals as potential outcomes

We use the terms potential outcomes and counterfactuals more or less interchangably in this book, but they are not technically identical in their meaning.
A counterfactual is a type of potential outcome, referring to a potential outcome that was not realized and is thus unobservable.
In a sense, the definition of a counterfactual depends on the exposure that actually happened.
Potential outcomes, though, are agnostic to the observed exposure and are often well-defined before it even happens.
Nevertheless, we're usually working with data after an exposure happens, and so we have one realized potential outcome and at least one potential outcome that is counter to the fact.
Some die-hards insist on one term or the other, but we find both useful.
:::

Let's consider a different example: the effect of ice cream on happiness.

### Does chocolate ice cream make you happier than vanilla? {#sec-po-sim}

Let's suppose some happiness index exists that ranges from 1-10.
We are interested in assessing whether eating chocolate ice cream versus vanilla will increase happiness.
We have 10 individuals with two potential outcomes for each, one is what their happiness would be if they ate chocolate ice cream, (defined as `y_chocolate` in the code below), and one is what their happiness would be if they ate vanilla ice cream (defined as `y_vanilla` in the code below).
We can define the true individual causal effect of eating chocolate ice cream (versus vanilla) on happiness for each individual as the difference between the two (@tbl-po).

```{r}
#| label: sim-generation
#| echo: false
#| eval: false
set.seed(1)
n <- 10
sim <- tibble(
  id = 1:n,
  favor_chocolate = rbinom(n, 1, 0.7),
  y_chocolate = round(runif(n, 3, 7), 0),
  y_vanilla = case_when(
    favor_chocolate == 1 ~ y_chocolate - rbinom(n, 3, 0.5),
    TRUE ~ y_chocolate + rbinom(n, 2, 0.5)
  ),
  y_cookiesandcreme = round(runif(n, 1, 5), 0),
  diff = y_chocolate - y_vanilla
)
```

```{r}
#| results: hide
data <- data.frame(
  id = 1:10,
  y_chocolate = c(4, 4, 6, 5, 6, 5, 6, 7, 5, 6),
  y_vanilla = c(1, 3, 4, 5, 5, 6, 8, 6, 3, 5)
)

data <- data |>
  mutate(causal_effect = y_chocolate - y_vanilla)

data
```

```{r}
#| label: tbl-po
#| tbl-cap: "Potential Outcomes Simulation: The causal effect of eating chocolate (versus vanilla) ice cream on happiness. In this simulation, each individual has a known outcome for each exposure. Since we know each potential outcome, we can calculate the individual causal effects on happiness of eating chocolate versus vanilla ice cream."
#| echo: false
library(gt)
data |>
  gt() |>
  cols_label(
    id = "ID",
    y_chocolate = md("$$Y_{\\text{id}}(\\text{chocolate})$$"),
    y_vanilla = md("$$Y_{\\text{id}}(\\text{vanilla})$$"),
    causal_effect = md("$$Y_{\\text{id}}(\\text{chocolate}) - Y_{\\text{id}}(\\text{vanilla})$$")
  ) |>
  fmt_markdown(
    columns = c(y_chocolate, y_vanilla, causal_effect)
  ) |>
  tab_header(
    title = md("**Potential Outcomes and Causal Effect**")
  ) |>
  tab_spanner(
    label = "Potential Outcomes",
    columns = c(y_chocolate, y_vanilla)
  ) |>
  tab_spanner(
    label = "Causal Effect",
    columns = causal_effect
  )
```

For example, examining @tbl-po, the causal effect of eating chocolate ice cream (versus vanilla) for individual `4` is `r data |> filter(id == 4) |> pull(causal_effect)`, whereas the causal effect for individual `9` is `r data |> filter(id == 9) |> pull(causal_effect)`.

The *average* potential happiness after eating chocolate is `r mean(data |> pull(y_chocolate))` and the *average* potential happiness after eating vanilla is `r mean(data |> pull(y_vanilla))`.
The *average* treatment effect of eating chocolate (versus vanilla) ice cream among the ten individuals in this study is `r mean(data |> pull(causal_effect))`.

```{r}
data |>
  summarize(
    avg_chocolate = mean(y_chocolate),
    avg_vanilla = mean(y_vanilla),
    avg_causal_effect = mean(causal_effect)
  )
```

In reality, we cannot observe both potential outcomes, in any moment in time; each individual in our study can only eat *one* flavor of ice cream.
Suppose we randomly gave one flavor or the other to each participant.
Now what we *observe* is shown in @tbl-obs.
We only know one potential outcome (the one related the the exposure the participant received).
We don't know the other one, and consequently, we don't know the individual causal effect.

```{r}
## we are doing something *random* so let's
## set a seed so we always observe the
## same result each time we run the code
set.seed(11)
data_observed <- data |>
  mutate(
    # change the exposure to randomized, generate from 
    # a binomial distribution with a probability 0.5 for 
    # being in either group
    exposure = case_when(
      rbinom(n(), 1, 0.5) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    ),
    observed_outcome = case_when(
      exposure == "chocolate" ~ y_chocolate,
      exposure == "vanilla" ~ y_vanilla
    )
  ) |>
  select(id, exposure, observed_outcome, starts_with("y"))
```

```{r}
#| label: tbl-obs
#| tbl-cap: "Potential Outcomes Simulation: The observed exposure is the only potential outcome we know. We don't know the missing potential outcome and thus we cannot calculate the individual causal effect. We need to use the observed exposure and outcome used to estimate the effect of eating chocolate (versus vanilla) ice cream on happiness, but we can't do it at the individual level."
#| echo: false
avg_chocolate <- data_observed |>
  filter(exposure == "chocolate") |>
  pull(observed_outcome) |>
  mean()

avg_vanilla <- data_observed |>
  filter(exposure == "vanilla") |>
  pull(observed_outcome) |>
  mean()

data_observed |>
  mutate(
    y_chocolate = ifelse(exposure == "chocolate", y_chocolate, NA),
    y_vanilla = ifelse(exposure == "vanilla", y_vanilla, NA),
    causal_effect = NA_real_
  ) |>
  select(-observed_outcome) |>
  gt() |>
  cols_label(
    id = "ID",
    y_chocolate = md("$$Y_{\\text{id}}(\\text{chocolate})$$"),
    y_vanilla = md("$$Y_{\\text{id}}(\\text{vanilla})$$"),
    causal_effect = md("$$Y_{\\text{id}}(\\text{chocolate}) - Y_{\\text{id}}(\\text{vanilla})$$")
  ) |>
  fmt_markdown(columns = c(y_chocolate, y_vanilla, causal_effect)) |>
  sub_missing(
    columns = c(y_chocolate, y_vanilla, causal_effect),
    missing_text = md("---") # Format missing values as blank
  ) |>
  tab_header(
    title = md("**Potential Outcomes and Hidden Causal Effect**")
  ) |>
  tab_spanner(
    label = "Potential Outcomes",
    columns = c(y_chocolate, y_vanilla)
  ) |>
  tab_spanner(
    label = "Causal Effect",
    columns = causal_effect
  )
```

Now, the observed average outcome among those who ate chocolate ice cream is `r round(avg_chocolate, 1)`, while the observed average outcome among those who ate vanilla is `r round(avg_vanilla, 1)`.
These are quite close to the actual averages, despite the fact that we are now missing the counterfactual outcomes.
The estimated average causal effect is `r round(avg_chocolate, 1)` - `r round(avg_vanilla, 1)` = `r round(avg_chocolate - avg_vanilla, 1)`.
We're a little off because of the low sample size, but as it increased, we would get a more exact answer.

```{r}
data_observed |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

Why does this work, despite the fact that we can no longer calculate the true causal effect?
Randomization, it turns out, has the properties we need to meet causal assumptions about observed data.
Because these assumptions are met, we can use the observed averages as proxies for averages of the two potential outcomes.

Let's see why this is and what happens when those assumptions are violated.

## Causal assumptions

We'll discuss many methods throughout this book.
Each method comes with a set of unverifiable assumptions we need to make the interpret the results as causal.
These assumptions have one goal: to allow us to used observed data to represent unobservable counterfactuals.
What does it require for us to be able to do this?

::: callout-note
## Apples-to-apples

Practically, most of the assumptions we need to make for causal inference are so we can make an *apples-to-apples* comparison: we want to make sure we're comparing individuals that are similar --- who would serve as good proxies for each other's counterfactuals.

The phrase *apples-to-apples* stems from the saying "comparing apples to oranges", e.g. comparing two things that are incomparable.

That's only one way to say it.
[There are a lot of variations worldwide](https://en.wikipedia.org/wiki/Apples_and_oranges).
Here are some other things people incorrectly compare:

-   Cheese and chalk (UK English)
-   Apples and pears (German)
-   Potatoes and sweet potatoes (Latin American Spanish)
-   Grandmothers and toads (Serbian)
-   Horses and donkeys (Hindi)
:::

For the first three-fourths or so of the book, we'll deal with so-called *unconfoundedness* methods.
These methods all assume[^03-estimating-counterfactuals-1] three things: exchangeability, positivity, and consistency.
We'll focus on these three assumptions for now, but other methods, such as instrumental variable analysis (@sec-iv-friends) and difference-in-differences (@sec-did), make other causal assumptions.
Knowing a method's assumptions is important for using it correctly, but it's also worth considering if another method's assumptions are more feasible for the problem you are trying to solve.

[^03-estimating-counterfactuals-1]: These *causal* assumptions are in addition to any *statistical* assumptions, such as distributional assumptions, that the estimators we use require.

::: callout-note
These assumptions are sometimes referred to as *identifiability conditions* since we need them to hold in order to identify causal estimates.
Likewise, you'll sometimes see people discussing whether or not a given causal effect is "identifiable."
:::

### Exchangeability

The exchangeability assumption is the hallmark of unconfoundedness methods like inverse probability weighting and regression adjustment.
Here, we assume that each exposure group has the same potential outcomes on average.
So, the group that was assigned "chocolate" ice cream has the same potential outcomes for happiness for chocolate as the vanilla group (had *they* been assigned to chocolate).
Mathematically, exchangeability is written as $Y(x) \perp\!\!\!\perp X$.
Exposure *status* is independent of the potential outcomes; being in the chocolate group, for instance, doesn't change what your potential outcome would have been in the vanilla group.
When this assumption holds, it allows use to treat the vanilla group as the proxy for the chocolate group's `y(vanilla)` and vice versa, as in @fig-po.

```{r}
#| label: fig-po
#| fig-cap: "The average potential outcomes by observed exposure group. Under exchangeability, the exposure groups have nothing to do with the potential outcomes themselves. Had the vanilla group recieved chocolate, their potential outcomes are about the same on average as the chocolate group, and vice versa. Exchangeability allows us to use each group as a counterfactual for the other."
#| code-fold: true
data_observed |>
  select(starts_with("y"), exposure) |>
  pivot_longer(
    starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(potential_outcome = paste0("y(", potential_outcome, ")")) |>
  ggplot(aes(happiness, exposure, color = exposure)) +
  geom_jitter(width = 0, height = .2, alpha = .5, color = "grey50") +
  stat_summary(fun = "mean", size = 2.5, geom = "point") +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black"
  ) +
  facet_wrap(~potential_outcome) +
  labs(y = "actual exposure", color = "actual\nexposure")
```

::: callout-note
Exchangeability is sometimes called the "no confounding" or "unconfoundedness" assumption.
It's also sometimes called "ignorability."
:::

Exchangeability is guaranteed in the limit when you randomize the exposure, as we did earlier with ice cream flavors.
If you think about exchangeability from a randomization process, you can see where the name comes from.
Let's say we mixed up the labels for who got which flavor, and we accidentally gave chocolate to the "vanilla" group and vanilla to the "chocolate" group.
Because flavor assignment is independent of the potential outcomes, this mix up doesn't matter.
We've exchanged the groups by flipping their assignments, but we can still detect the right causal effect [^03-estimating-counterfactuals-2].

[^03-estimating-counterfactuals-2]: The numbers are a little different because of the sample size.
    As the sample size increases, exchangability is more likely to hold with randomization, and so with a large enough sample, we'd get identical answers.

```{r}
set.seed(11)

mix_up <- function(flavor) {
  ifelse(flavor == "chocolate", "vanilla", "chocolate")
}

data_observed <- data |>
  mutate(
    exposure = case_when(
      rbinom(n(), 1, 0.5) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    ),
    exposure = mix_up(exposure),
    observed_outcome = case_when(
      exposure == "chocolate" ~ y_chocolate,
      exposure == "vanilla" ~ y_vanilla
    )
  )

data_observed |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

So, what does it mean for exchangeability to be violated?
Let's say, instead, we allowed each participant to select their own ice cream flavor.
80% of the time, participants chose the flavor that made them happiest---their preference.

```{r}
set.seed(11)
data_observed_exch <- data |>
  mutate(
    prefer_chocolate = y_chocolate > y_vanilla,
    exposure = case_when(
      # people who like chocolate more chose that 80% of the time
      prefer_chocolate ~ ifelse(
        rbinom(n(), 1, 0.8), 
        "chocolate", 
        "vanilla"
      ),
      # people who like vanilla more chose that 80% of the time
      !prefer_chocolate ~ ifelse(
        rbinom(n(), 1, 0.8), 
        "vanilla",
        "chocolate"
      )
    ),
    observed_outcome = case_when(
      exposure == "chocolate" ~ y_chocolate,
      exposure == "vanilla" ~ y_vanilla
    )
  ) |>
  select(
    id, prefer_chocolate, exposure, 
    observed_outcome, starts_with("y")
  )
```

Now, it seems like vanilla makes you happier!

```{r}
data_observed_exch |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

Why does this happen?
We'll dive more deeply into this problem in @sec-dags and beyond, but from an assumptions perspective, it's that exchangeability no longer holds.
The potential outcomes are no longer the same on average by the two exposure groups.
The average values for `y(chocolate)` are still pretty close, but `y(vanilla)` is quite different by group.
The vanilla group no longer serves as a good proxy for this potential outcome for the chocolate group, and we get a biased result.
What we're seeing here is actually the potential outcomes for `y(flavor, preference)`.
This is always true because there are individuals who for whom the individual causal effect is not 0.
What's changed is that the potential outcomes are longer independent of which `flavor` a person has: their preference influences both the choice of flavor and the potential outcome. As we see in @fig-po-confounding, our groups are no longer exchangeable; they don't have the same potential outcomes on average for `y(vanilla)`.

```{r}
#| label: "fig-po-confounding"
#| fig-cap: "The average potential outcomes by observed exposure group in the presence of confounding. Because the flavor assignment is no longer independent of the potential outcomes, the groups are no longer exchangeable."
#| code-fold: true
data_observed_exch |>
  select(starts_with("y"), exposure) |>
  pivot_longer(
    starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(potential_outcome = paste0("y(", potential_outcome, ")")) |>
  ggplot(aes(happiness, exposure, color = exposure)) +
  geom_jitter(width = 0, height = .2, alpha = .5, color = "grey50") +
  stat_summary(fun = "mean", size = 2.5, geom = "point") +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black"
  ) +
  facet_wrap(~potential_outcome) +
  labs(y = "actual exposure", color = "actual\nexposure")
```

What can we do when exchangeability is violated?
We'll devote a substantial amount of time to this problem throughout the book.
The heart of the solution, though, is that we can sometimes still achieve exchangeability within levels of another variable.
This is called *conditional* exchangeability: $Y(x) \perp\!\!\!\perp X \mid Z$
In this case, we need exchangeability within levels of `prefer_chocolate`.

```{r}
#| label: fig-po-cond-exch
#| fig-cap: "The average potential outcomes by observed exposure group in the presence of confounding. We can still acheive *conditional* exchangeability within levels of the confounder. Here, we also start to see the limits of our sample size, as the potential outcomes, which would be valid in higher numbers, start to fail."
#| code-fold: true
data_observed_exch |>
  mutate(prefer_chocolate = ifelse(
    prefer_chocolate,
    "prefers\nchocolate",
    "prefers\nvanilla"
  )) |>
  pivot_longer(
    starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(potential_outcome = paste0("y(", potential_outcome, ")")) |>
  ggplot(aes(happiness, exposure, color = exposure)) +
  geom_jitter(width = 0, height = .2, alpha = .5, color = "grey50") +
  stat_summary(fun = "mean", size = 2.5, geom = "point") +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black"
  ) +
  facet_grid(prefer_chocolate ~ potential_outcome) +
  labs(y = "actual exposure", color = "actual\nexposure")
```

::: callout-warning
In @fig-po-cond-exch, we've already started to encounter the curse of dimensionality: our sample size is so small, that we have very few values by combination of exposure and preference.
As our sample size increases, we'd achieve better exchangeability, but it quickly becomes hard to do without a good statistical model.
:::

### Positivity

The positivity assumption states that every individual has a non-zero probability of receiving each level of exposure. Mathematically, this means that $P(X = x) > 0 \quad \text{for all } x$
In other words, we assume that there is no one for whom one or more levels of exposure are impossible.
The reason we need this assumption is that it defines the potential outcome for a given exposure level.
If someone is never, under any circumstances, exposed to chocolate, then the potential outcome for `y(chocolate)` isn't defined for that person.
We can't use them to provide information about this potential outcome.
In a randomized trial, the probability of exposure is known by design.
In the ice cream example, everyone had the same probabilities: 50% to receive chocolate and 50% to receive vanilla.
This defines both potential outcomes for both groups.

::: callout-note
Sometimes, positivity is referred to as the **probabilistic** assumption.
:::

Positivity violations come in two forms: stochastic and structural.
Stochastic violations are chance occurrences where you don't have any observations for a given exposure level.
In the example where 80% of participants chose the ice cream that would make them happiest, it's feasible that, given our low sample size, we might end up with people who only choose chocolate.
Naturally, we can't calculate the effect of vanilla vs. chocolate if we don't have any observations of vanilla.

A nuance of positivity is that it needs to hold within levels of all covariates required for exchangability: $P(X = x \mid Z = z) > 0 \quad \text{for all } x \text{ and } z$
Even if we end up with variability in the flavors, we *also* need variability within levels of `prefer_chocolate`.
That can also fail by chance.

```{r}
set.seed(1)
data_observed_pos <- data |>
  mutate(
    prefer_chocolate = y_chocolate > y_vanilla,
    exposure = case_when(
      prefer_chocolate ~ ifelse(
        rbinom(n(), 1, 0.8), 
        "chocolate", 
        "vanilla"
      ),
      !prefer_chocolate ~ ifelse(
        rbinom(n(), 1, 0.8), 
        "vanilla",
        "chocolate"
      )
    ),
    observed_outcome = case_when(
      exposure == "chocolate" ~ y_chocolate,
      exposure == "vanilla" ~ y_vanilla
    )
  )

data_observed_pos |>
  count(prefer_chocolate, exposure) |>
  complete(
    prefer_chocolate,
    exposure = c("chocolate", "vanilla"),
    fill = list(n = 0)
  )
```

Structural positivity violations are when an individual cannot receive at least one value of the exposure by definition.
Let's say some of our participants had an allergy to vanilla.

```{r}
set.seed(11)
data_observed_struc <- data |>
  mutate(
    exposure = case_when(
      rbinom(n(), 1, 0.5) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    )
  )

set.seed(1)
data_observed_struc <- data_observed_struc |>
  mutate(
    # 30% chance of allergy
    allergy = rbinom(n(), 1, 0.3) == 1,
    # in which case `y_vanilla` is impossible
    exposure = ifelse(allergy, "chocolate", exposure),
    y_vanilla = ifelse(allergy, NA, y_vanilla),
    observed_outcome = case_when(
      # those with allergies always take chocolate
      allergy ~ y_chocolate,
      exposure == "chocolate" ~ y_chocolate,
      exposure == "vanilla" ~ y_vanilla
    )
  )
```

Now are estimates are off quite a bit.

```{r}
data_observed_struc |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

For those who have a vanilla allergy, `y_vanilla` is not defined, as in @fig-po-pos.

```{r}
#| label: "fig-po-pos"
#| fig-cap: "Potential outcomes in the presence of a structural positivity violation. When it's not possible for potential outcomes to occur, they are not defined. Those who have an allergy to vanilla do not have a counterpart `y(vanilla)`."
#| code-fold: true
#| warning: false
data_observed_struc |>
  mutate(is_missing_y_vanilla = is.na(y_vanilla)) |>
  select(starts_with("y"), exposure, is_missing_y_vanilla) |>
  pivot_longer(
    starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(
    potential_outcome = paste0("y(", potential_outcome, ")")
  ) |>
  ggplot(aes(happiness, exposure)) +
  geom_jitter(
    data = \(.x) filter(.x, !is_missing_y_vanilla),
    width = 0,
    height = .2,
    alpha = .5,
    color = "grey50"
  ) +
  geom_jitter(
    data = \(.x) filter(.x, is_missing_y_vanilla),
    aes(
      color = "missing y(vanilla) counterpart",
      fill = "missing y(vanilla) counterpart"
    ),
    size = 2,
    width = 0,
    height = .2,
    alpha = .8,
    shape = 21
  ) +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black",
    size = 3
  ) +
  stat_summary(fun = "mean", size = 2, geom = "point") +
  facet_wrap(~potential_outcome) +
  labs(y = "Actual Exposure", color = NULL, fill = NULL)
```

There are a few things we can do to improve positivity problems.
For stochastic positivity violations, we can collect more data.
Increasing the sample size reduces the chances of stochastic violations.
However, because we require positivity with each combination of covariates, we often need to lean on a statistical model to extrapolate over the dimensionality of the data.
We'll discuss this topic more in [Chapter -@sec-ps] and [Chapter -@sec-g-comp].
Additionally, we can specify eligibility criteria (which we'll discuss in @sec-target-trial) to exclude people for whom some level of exposure is not possible.
If positivity is an issue within a particular confounder, we could also consider removing the confounder; if the confounding bias induced by not controlling for it is less than the bias induced by positivity, it might be worth the trade.
Finally, we can modify the causal estimand we are trying to estimate.
As we'll see in [Chapter -@sec-estimands], different causal effects have different strictness in terms of meeting the causal assumptions.

### Consistency

Consistency assumes that the causal question you claim you are answering is consistent with the one you are *actually* answering with your analysis. 
Consistency allows us to see one of the potential outcomes for each group: the factual outcome.
Mathematically, this means that $Y_{obs} = (X)Y(1) + (1 - X)Y(0)$.
In plain language, the consistency assumption says that the potential outcome of a given treatment value is equal to the value we actually observe when someone is assigned that treatment value.
It seems almost silly when you say it.
What else would it be?
If you think this issue through, though, you'll see that many times there are a near infinite violations of this assumption for any given exposure.
Let's consider two common cases:

-   **Poorly-defined exposure**: For each value of the exposure, there is a difference between subjects in the delivery of that exposure. Put another way, multiple versions of the treatment exist; we assume a *well-defined exposure*.
-   **Interference**: The outcome (technically all *potential* outcomes, regardless of whether they are observed) for any subject does depends on another subject's exposure; we assume *no interference*.

::: callout-tip
Consistency is sometimes referred to as the *stable-unit-treatment-value assumption* or **SUTVA** [@imbens2015causal].
However, it is a distinct idea from *statistical* consistency, which is a property where an estimator moves closer to the truth as the sample size increases
:::

#### Poorly-defined exposures

Consistency violations are common when an exposure is poorly defined.
They occur in everything from surgeries (say if one doctor is more experienced with a surgery than another), income (are all income sources dollar-for-dollar the same? Is the lottery the same as a weekly paycheck?), education (do years of education have the same effect across school quality?), and many others [@Rehkopf2016].

Suppose that there were in fact two containers of chocolate ice cream, one of which was spoiled.
Having an exposure "chocolate" could mean different things depending on where the individual's scoop came from (regular chocolate ice cream or spoiled chocolate ice cream); we are lumping them all together under a single term.
Eating the spoiled ice cream, of course, makes you miserable, regardless of how you feel about chocolate ice cream in general.

```{r}
data <- data.frame(
  id = 1:10,
  y_spoiled_chocolate = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0),
  y_chocolate = c(4, 4, 6, 5, 6, 5, 6, 7, 5, 6),
  y_vanilla = c(1, 3, 4, 5, 5, 6, 8, 6, 3, 5)
) |>
  mutate(causal_effect = y_chocolate - y_vanilla)

set.seed(11)
data_observed_poorly_defined <- data |>
  mutate(
    exposure_unobserved = case_when(
      rbinom(n(), 1, 0.25) == 1 ~ "chocolate (spoiled)",
      rbinom(n(), 1, 0.25) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    ),
    observed_outcome = case_match(
      exposure_unobserved,
      "chocolate (spoiled)" ~ y_spoiled_chocolate,
      "chocolate" ~ y_chocolate,
      "vanilla" ~ y_vanilla
    ),
    exposure = case_match(
      exposure_unobserved,
      c("chocolate (spoiled)", "chocolate") ~ "chocolate",
      "vanilla" ~ "vanilla"
    )
  ) |>
  select(
    id, exposure, observed_outcome,
    exposure_unobserved, starts_with("y")
  )
```

We know the *true* average causal effect of (unspoiled) chocolate in the sample is `r mean(data |> pull(causal_effect))`, however our estimated causal effect (because our data are not consistent with the question we are asking) is `r data_observed |> group_by(exposure) |> summarise(avg_outcome = mean(observed_outcome)) |> mutate(exposure = c(1, 0)) |> pivot_wider(names_from = exposure, values_from = avg_outcome, names_prefix = "x_") |> summarise(estimate = x_1 - x_0) |> pull() |> round(1)`.

```{r}
data_observed_poorly_defined |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

The potential outcome we think we are estimating is not the one we are actually observing.
We're treating fresh chocolate ice cream and spoiled chocolate ice cream as the same exposure, but they have different effects on the potential outcomes.
Because the exposure is random, we actually do a pretty good job of estimating the effect of `y(chocolate | spoiled_chocolate)`, but that's not what we're interested in.
We want `y(chocolate, spoiled = FALSE)`.

```{r}
#| label: "fig-po-cons"
#| fig-cap: "Potential outcomes under a consistency violation. Consistency allows us to treat the observed data as the factual outcome. Here, we're treating the chocolate group as representative of `y(chocolate)`, but this isn't true. The data represent a mixture of `y(chocolate, spoiled = FALSE)` and `y(chocolate, spoiled = TRUE)`, different potential outcomes."
#| code-fold: true
data_observed_poorly_defined |>
  mutate(
    is_spoiled = exposure_unobserved == "chocolate (spoiled)"
  ) |>
  pivot_longer(
    cols = starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(
    potential_outcome = case_when(
      potential_outcome == "spoiledchocolate" ~ "chocolate",
      TRUE ~ potential_outcome
    ),
    potential_outcome = paste0("y(", potential_outcome, ")")
  ) |>
  ggplot(aes(happiness, exposure)) +
  geom_jitter(
    data = \(.x) filter(.x, !(potential_outcome == "y(chocolate)" & exposure == "chocolate")),
    width = 0,
    height = 0.2,
    alpha = 0.5,
    color = "grey50"
  ) +
  geom_jitter(
    data = \(.x) filter(.x, potential_outcome == "y(chocolate)" & exposure == "chocolate"),
    aes(color = is_spoiled, fill = is_spoiled),
    size = 2,
    width = 0,
    height = 0.2,
    alpha = 0.8,
    shape = 21
  ) +
  stat_summary(
    fun = "mean",
    size = 2,
    geom = "point"
  ) +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black",
    size = 3
  ) +
  facet_wrap(~potential_outcome) +
  labs(
    y = "actual exposure",
    color = "spoiled",
    fill = "spoiled"
  )
```

We can imagine other ways in which there are slight variations in the treatment: a high-quality brand of vanilla ice cream and a low-quality brand of vanilla ice cream are both categorized as "vanilla".
One person eats in in the morning and another in the afternoon.
One has a spoonful, and one has three bowls full.
There will almost always be *some* violation of consistency in this sense; the question for us is whether or not that violation is meaningful in terms of the potential outcomes we are seeing.
If two brands of ice cream produce the same happiness, this variation doesn't matter.
If they differ, by how much?

One of the things we can do to address consistency violations besides being more specific to begin with is investigate potential deviations within treatment levels.
Let's say we tested the ice cream containers after the experiment and had data as to the spoiled status of the ice cream in the data.
Now we can group it by it's true exposure.

```{r}
data_observed_poorly_defined |>
  group_by(exposure_unobserved) |>
  summarise(avg_outcome = mean(observed_outcome))
```

Now we're back to the right answer because we've correctly separated the potential outcomes in our analysis, as in @fig-po-const-defined.

```{r}
#| label: "fig-po-const-defined"
#| fig-cap: "Potential outcomes under a consistency violation. Now we've correctly linked the observed data to their underlying potential outcome, making them consistent."
#| code-fold: true
data_observed_poorly_defined |>
  pivot_longer(
    starts_with("y"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(potential_outcome = paste0("y(", potential_outcome, ")")) |>
  ggplot(aes(happiness, exposure_unobserved, color = exposure_unobserved)) +
  geom_jitter(width = 0, height = .2, alpha = .5, color = "grey50") +
  stat_summary(fun = "mean", size = 2.5, geom = "point") +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black"
  ) +
  facet_wrap(~potential_outcome) +
  labs(y = "true exposure", color = NULL)
```

#### Interference

Interference means that an individual's exposure impacts another's potential outcome.
It's very common in infectious disease, where someone's exposure to a vaccine or treatment often impacts someone else's outcome risk.
But it can also occur in a variety of other settings, including via social networks, policy interventions, geographic proximity of treated units, and so on.

Let's say each individual in our ice cream study has a partner, and their potential outcome depends on both what flavor of ice cream they ate *and* what flavor their partner ate.
In the simulation below, having a partner that received a *different* flavor of ice cream increases their happiness by two units.

```{r}
data <- data.frame(
  id = 1:10,
  partner_id = c(1, 1, 2, 2, 3, 3, 4, 4, 5, 5),
  y_chocolate_chocolate = c(4, 4, 6, 5, 6, 5, 6, 7, 5, 6),
  y_vanilla_vanilla = c(1, 3, 4, 5, 5, 6, 8, 6, 3, 5)
) |>
  # partner's happiness increases by 2
  # when they get a different flavor
  mutate(
    y_chocolate_vanilla = y_chocolate_chocolate + 2,
    y_vanilla_chocolate = y_vanilla_vanilla + 2
  )

set.seed(37)
data_observed_interf <- data |>
  mutate(
    exposure = case_when(
      rbinom(n(), 1, 0.5) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    ),
    exposure_partner = case_when(
      rbinom(n(), 1, 0.5) == 1 ~ "chocolate",
      TRUE ~ "vanilla"
    ),
    observed_outcome = case_when(
      exposure == "chocolate" & exposure_partner == "chocolate" ~ 
        y_chocolate_chocolate,
      exposure == "chocolate" & exposure_partner == "vanilla" ~
        y_chocolate_vanilla,
      exposure == "vanilla" & exposure_partner == "chocolate" ~ 
        y_vanilla_chocolate,
      exposure == "vanilla" & exposure_partner == "vanilla" ~ 
        y_vanilla_vanilla
    )
  )
```

As with a poorly-defined exposure, we don't get the right answer under interference.

```{r}
data_observed_interf |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

As before, the problem is that we're estimating the wrong potential outcome (@fig-const-interf).
Interference and poorly-defined exposures are different manifestations of the same assumption violation.
The potential outcomes we are estimating are not consistent with the causal question.

```{r}
#| label: "fig-const-interf"
#| fig-cap: "Potential outcomes under a consistency violation. This time, the vanilla group's `y(vanilla)` and the chocolate group's `y(chocolate)` are not correct: they are a mixture of effects due to interference by the partner's flavor."
#| code-fold: true
data_observed_interf |>
  pivot_longer(
    cols = starts_with("y_"),
    names_prefix = "y_",
    names_to = "potential_outcome",
    values_to = "happiness"
  ) |>
  mutate(
    potential_outcome = case_when(
      grepl("chocolate", potential_outcome) ~ "y(chocolate)",
      grepl("vanilla", potential_outcome) ~ "y(vanilla)"
    ),
    observed = case_when(
      potential_outcome == "y(chocolate)" & exposure == "chocolate" ~ TRUE,
      potential_outcome == "y(vanilla)" & exposure == "vanilla" ~ TRUE,
      TRUE ~ FALSE
    ),
    flavor_match = ifelse(exposure == exposure_partner, "Same Flavors", "Different Flavors") # Collapse to same/different
  ) |>
  ggplot(aes(happiness, exposure)) +
  geom_jitter(
    data = \(.x) filter(.x, !observed),
    width = 0,
    height = 0.2,
    alpha = 0.5,
    color = "grey50"
  ) +
  geom_jitter(
    data = \(.x) filter(.x, observed),
    aes(color = flavor_match, fill = flavor_match),
    size = 2,
    width = 0,
    height = 0.2,
    alpha = 0.8,
    shape = 21
  ) +
  stat_summary(
    fun = "mean",
    size = 2,
    geom = "point",
    color = "black"
  ) +
  stat_summary(
    fun = "mean",
    geom = "text",
    aes(label = round(after_stat(x), 1)),
    vjust = -0.6,
    color = "black",
    size = 3
  ) +
  facet_wrap(~potential_outcome) +
  labs(
    y = "Exposure",
    x = "Happiness",
    color = "Flavors",
    fill = "Flavors"
  )
```

As before, we can be more specific about the potential outcomes.

```{r}
data_observed_interf |>
  group_by(exposure, exposure_partner) |>
  summarise(avg_outcome = mean(observed_outcome), .groups = "drop")
```

One of the main ways to combat interference is change the *unit* under consideration.
Here, each individual, each unique *ID*, is considered a unit, and there is interference between units (i.e. between partners).
If instead we consider each *partner* as a unit and randomize the partners rather than the individuals, we solve the interference issue, as there is not interference *between* different partner sets.
This is sometimes referred to as a cluster randomized trial.
What we decide to do within each cluster may depend on the causal question at hand.
For example, if we want to know what would happen if *everyone* ate chocolate ice cream versus if *everyone* ate vanilla, we would want to randomize both partners to either chocolate or vanilla, as seen below.

```{r}
set.seed(11)

## we are now randomizing the *partners* not the individuals
partners <- data.frame(
  partner_id = 1:5,
  exposure = case_when(
    rbinom(5, 1, 0.5) == 1 ~ "chocolate",
    TRUE ~ "vanilla"
  )
)
partners_observed <- data |>
  left_join(partners, by = "partner_id") |>
  mutate(
    # all partners have the same exposure
    exposure_partner = exposure,
    observed_outcome = case_when(
      exposure == "chocolate" & exposure_partner == "chocolate" ~
        y_chocolate_chocolate,
      exposure == "vanilla" & exposure_partner == "vanilla" ~
        y_vanilla_vanilla
    )
  ) |>
  select(id, exposure, observed_outcome)
```

Now, we can detect the correct causal effect.

```{r}
partners_observed |>
  group_by(exposure) |>
  summarise(avg_outcome = mean(observed_outcome))
```

::: callout-note
There are also methods for identifying effects with multiple versions of treatments or interference, but they are technical and more limited by virtue of their consistency violations [@Tchetgen2012; @VanderWeele2013].
:::

Similarly, we could assign either the same flavor or different flavors among partners, which would allow us to calculate the cross-flavor effect.
Another option would be to exclude partners so there is no interference effect.
The key is to think about what you want to estimate and try to get as precise of a representation of the potential outcomes for that question as possible.

::: callout-note
## Malaria nets, revisited

In @sec-whole-game, we estimated the causal effect of mosquito nets on malaria risk.
Let's consider the causal assumptions for this question and how they might have been violated in a real-life analysis.

- **Exchangeability**: We saw what can happen with this problem when we having an unmeasured confounder (in this case, a genetic resistance to malaria).
Thinking about exchangeability is one of the harder but also one of the more common tasks in causal inference with observational data.
We'll discuss this in depth in @sec-dags and what to do if we think (or know) we're wrong in @sec-sensitivity.
We should also be concerned that we haven't measured the covariates we need well or are missing values (@sec-missingness).
- **Positivity**: A positivity violation would occur if any household would *always* or *never* use a bed net.
This is feasible in real life.
Someone may have an allergy to the material, or one type of net could be unapproved in a region.
As mentioned, we also need positivity to hold within levels of the combinations confounders in the analysis.
Is it possible, for instance, that someone of low economic status in cold weather (when mosquitoes are not very active) and good health would never use a bed net because it wasn't worth the expense?
- **Consistency**: We already saw an example of the well-defined exposure problem: a "bed net" can mean many things.
We decided we were comparing insecticide-treated bed nets compared to no nets, but that may not be enough.
Does the manufacturer matter?
The type of insecticide?
The amount of insecticide?
We need to think hard about what the effect on the potential outcomes each of these variations might have.
Interference is a real problem for bed-net research, particularly for insecticidal nets.
(spillover, houses-as-units) Notably, we used households as the unit of observation, which would reduce some of the local interference.
We could also consider households that are geographically dispersed from one another.
:::

## Planning studies with causal assumptions in mind

### Randomized trials

### Target trial emulation {#sec-target-trial}

-- exclusion: vanilla allergy

## When do standard methods succeed?

### Correlation is sometimes causation, actually

### Causal inference with `group_by()` and `summarize()`

## When do standard methods fail?

-   list of bad things!

### Causal methods in randomized trials
